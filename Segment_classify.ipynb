{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adagrad, RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "import glob\n",
    "import cv2\n",
    "import itertools\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.vq import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from keras import backend as K\n",
    "from skimage.io import imshow\n",
    "K.set_image_data_format('channels_last')\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtain images for segementation\n",
    "def get_imgs(file_path):\n",
    "    \n",
    "    img_arr = list()\n",
    "    gt_img_arr = list()\n",
    "    \n",
    "    for filename in glob.glob(file_path):\n",
    "        \n",
    "        gt_filename = '/Users/prajwal967/Desktop/AI_Assignment/gt/'+filename[48:60]+'_segmentation.png'\n",
    "\n",
    "        img = cv2.imread(filename)\n",
    "        gt_img = cv2.imread(gt_filename)\n",
    "        \n",
    "        gt_img = rgb_to_gray(gt_img)\n",
    "\n",
    "        img = cv2.resize(img,(128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "        gt_img = cv2.resize(gt_img,(128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        img_arr.append(img)\n",
    "        gt_img_arr.append(gt_img)\n",
    "        \n",
    "    return [img_arr, gt_img_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtain images for classification\n",
    "def get_imgs_classify(file_path, label_data):\n",
    "    \n",
    "    img_arr = list()\n",
    "    label = list()\n",
    "    \n",
    "    for filename in glob.glob(file_path): \n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img,(128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "        img_arr.append(img)\n",
    "        label.append(label_data)\n",
    "        \n",
    "    return [img_arr, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function converts the image to a numpy array\n",
    "def imgToarr(img):\n",
    "    \n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert image to grayscale\n",
    "def rgb_to_gray(color_img):\n",
    "    \n",
    "    img_gray = cv2.cvtColor(color_img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Resizes the image to the specified dimensions\n",
    "def resize(img,x,y):\n",
    "    \n",
    "    return img.resize((x,y),Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dice loss.\n",
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr, gt_arr = get_imgs('/Users/prajwal967/Desktop/AI_Assignment/segment/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = np.asarray(img_arr)\n",
    "ground_truth = np.asarray(gt_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth.reshape(ground_truth.shape[0], ground_truth.shape[1], ground_truth.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = ShuffleSplit(n_splits = 2, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data (Train and test)\n",
    "segment_index, y = split.split(img_arr)\n",
    "segment_train_X = img_arr[segment_index[0]]\n",
    "segment_train_Y = ground_truth[segment_index[0]]\n",
    "segment_test_X = img_arr[segment_index[1]]\n",
    "segment_test_Y = ground_truth[segment_index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue_mean = np.mean(segment_train_X[:,:,:,0])\n",
    "red_mean = np.mean(segment_train_X[:,:,:,1])\n",
    "green_mean = np.mean(segment_train_X[:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue_std = np.std(segment_train_X[:,:,:,0])\n",
    "red_std = np.std(segment_train_X[:,:,:,1])\n",
    "green_std = np.std(segment_train_X[:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_train_X = segment_train_X.astype('float32')\n",
    "segment_test_X = segment_test_X.astype('float32')\n",
    "segment_train_Y = segment_train_Y.astype('float32')\n",
    "segment_test_Y = segment_test_Y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_train_Y = segment_train_Y/255\n",
    "segment_test_Y = segment_test_Y/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_train_X[:,:,:,0] = segment_train_X[:,:,:,0] - blue_mean\n",
    "segment_train_X[:,:,:,1] = segment_train_X[:,:,:,1] - red_mean\n",
    "segment_train_X[:,:,:,2] = segment_train_X[:,:,:,2] - green_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_test_X[:,:,:,0] = segment_test_X[:,:,:,0] - blue_mean\n",
    "segment_test_X[:,:,:,1] = segment_test_X[:,:,:,1] - red_mean\n",
    "segment_test_X[:,:,:,2] = segment_test_X[:,:,:,2] - green_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_train_X[:,:,:,0] = segment_train_X[:,:,:,0]/blue_std\n",
    "segment_train_X[:,:,:,1] = segment_train_X[:,:,:,1]/red_std\n",
    "segment_train_X[:,:,:,2] = segment_train_X[:,:,:,2]/green_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segment_test_X[:,:,:,0] = segment_test_X[:,:,:,0]/blue_std\n",
    "segment_test_X[:,:,:,1] = segment_test_X[:,:,:,1]/red_std\n",
    "segment_test_X[:,:,:,2] = segment_test_X[:,:,:,2]/green_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the convolution neural network\n",
    "nb_epoch = 10\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segementation architecture.\n",
    "inputs = Input((128, 128, 3))\n",
    "\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.2445 - dice_coef: 0.2445 - acc: 0.7978Epoch 00001: val_acc improved from -inf to 0.79755, saving model to segment.h5\n",
      "1280/1280 [==============================] - 120s 93ms/step - loss: -0.2456 - dice_coef: 0.2456 - acc: 0.7978 - val_loss: -0.4088 - val_dice_coef: 0.4088 - val_acc: 0.7975\n",
      "Epoch 2/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.4851 - dice_coef: 0.4851 - acc: 0.8283Epoch 00002: val_acc improved from 0.79755 to 0.85306, saving model to segment.h5\n",
      "1280/1280 [==============================] - 109s 85ms/step - loss: -0.4860 - dice_coef: 0.4860 - acc: 0.8288 - val_loss: -0.5407 - val_dice_coef: 0.5407 - val_acc: 0.8531\n",
      "Epoch 3/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.5771 - dice_coef: 0.5771 - acc: 0.8572Epoch 00003: val_acc improved from 0.85306 to 0.85980, saving model to segment.h5\n",
      "1280/1280 [==============================] - 106s 83ms/step - loss: -0.5785 - dice_coef: 0.5785 - acc: 0.8573 - val_loss: -0.6025 - val_dice_coef: 0.6025 - val_acc: 0.8598\n",
      "Epoch 4/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6313 - dice_coef: 0.6313 - acc: 0.8718Epoch 00004: val_acc improved from 0.85980 to 0.86365, saving model to segment.h5\n",
      "1280/1280 [==============================] - 106s 83ms/step - loss: -0.6317 - dice_coef: 0.6317 - acc: 0.8718 - val_loss: -0.6334 - val_dice_coef: 0.6334 - val_acc: 0.8637\n",
      "Epoch 5/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6573 - dice_coef: 0.6573 - acc: 0.8799Epoch 00005: val_acc improved from 0.86365 to 0.89141, saving model to segment.h5\n",
      "1280/1280 [==============================] - 111s 86ms/step - loss: -0.6574 - dice_coef: 0.6574 - acc: 0.8802 - val_loss: -0.6710 - val_dice_coef: 0.6710 - val_acc: 0.8914\n",
      "Epoch 6/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6816 - dice_coef: 0.6816 - acc: 0.8912Epoch 00006: val_acc improved from 0.89141 to 0.89283, saving model to segment.h5\n",
      "1280/1280 [==============================] - 117s 91ms/step - loss: -0.6809 - dice_coef: 0.6809 - acc: 0.8909 - val_loss: -0.6877 - val_dice_coef: 0.6877 - val_acc: 0.8928\n",
      "Epoch 7/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6981 - dice_coef: 0.6981 - acc: 0.8950Epoch 00007: val_acc improved from 0.89283 to 0.89532, saving model to segment.h5\n",
      "1280/1280 [==============================] - 119s 93ms/step - loss: -0.6984 - dice_coef: 0.6984 - acc: 0.8950 - val_loss: -0.6998 - val_dice_coef: 0.6998 - val_acc: 0.8953\n",
      "Epoch 8/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7114 - dice_coef: 0.7114 - acc: 0.8992Epoch 00008: val_acc improved from 0.89532 to 0.89776, saving model to segment.h5\n",
      "1280/1280 [==============================] - 120s 94ms/step - loss: -0.7105 - dice_coef: 0.7105 - acc: 0.8990 - val_loss: -0.7100 - val_dice_coef: 0.7100 - val_acc: 0.8978\n",
      "Epoch 9/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7170 - dice_coef: 0.7170 - acc: 0.9008Epoch 00009: val_acc improved from 0.89776 to 0.90637, saving model to segment.h5\n",
      "1280/1280 [==============================] - 108s 84ms/step - loss: -0.7169 - dice_coef: 0.7169 - acc: 0.9006 - val_loss: -0.7231 - val_dice_coef: 0.7231 - val_acc: 0.9064\n",
      "Epoch 10/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7290 - dice_coef: 0.7290 - acc: 0.9022Epoch 00010: val_acc improved from 0.90637 to 0.90862, saving model to segment.h5\n",
      "1280/1280 [==============================] - 117s 91ms/step - loss: -0.7285 - dice_coef: 0.7285 - acc: 0.9023 - val_loss: -0.7297 - val_dice_coef: 0.7297 - val_acc: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b389278>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the segmentation model.\n",
    "model.compile(loss = dice_coef_loss, optimizer=Adam(lr=1e-5), metrics=[dice_coef, 'accuracy'])\n",
    "\n",
    "#Store the model.\n",
    "filepath = \"segment.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(segment_train_X, segment_train_Y, batch_size=batch_size, epochs = nb_epoch, callbacks=callbacks_list, \\\n",
    "          validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 11s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of segmentation\n",
    "score = model.evaluate(segment_test_X, segment_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.6045227051\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of segmentation\n",
    "print(score[2] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_melanoma, non_melanoma_label= get_imgs_classify('/Users/prajwal967/Desktop/AI_Assignment/others/*.jpg', 0)\n",
    "melanoma, melanoma_label= get_imgs_classify('/Users/prajwal967/Desktop/AI_Assignment/melanoma/*.jpg', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate([non_melanoma, melanoma])\n",
    "labels = np.concatenate([non_melanoma_label, melanoma_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the segmented image\n",
    "arr_segment = model.predict(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_segment_thresh = arr_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr_segment_thresh[arr_segment_thresh > 0.5] = 1\n",
    "arr_segment_thresh[arr_segment_thresh < 0.5] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform a stratified split. (Train and test)\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "train_test_split(arr_segment_thresh, labels, test_size=0.3, random_state=42, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing the values for the convolution neural network\n",
    "nb_epoch_classify = 10\n",
    "batch_size_classify = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prajwal967/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), input_shape=(128, 128,..., padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Classification architecture\n",
    "model_classify = Sequential()\n",
    "\n",
    "model_classify.add(Conv2D(128, (3, 3), border_mode='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "model_classify.add(Activation('relu'))\n",
    "model_classify.add(Conv2D(128, (3, 3)))\n",
    "model_classify.add(Activation('relu'))\n",
    "model_classify.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_classify.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model_classify.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model_classify.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_classify.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_classify.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_classify.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model_classify.add(Flatten())\n",
    "model_classify.add(Dense(4096, activation='relu'))\n",
    "model_classify.add(Dropout(0.2))\n",
    "model_classify.add(Dense(4096, activation='relu'))\n",
    "model_classify.add(Dropout(0.2))\n",
    "model_classify.add(Dense(nb_classes))\n",
    "model_classify.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1120 samples, validate on 280 samples\n",
      "Epoch 1/10\n",
      "1110/1120 [============================>.] - ETA: 5s - loss: 0.5578 - acc: 0.8036 - f1: 0.8088 Epoch 00001: val_acc improved from -inf to 0.78214, saving model to classify.h5\n",
      "1120/1120 [==============================] - 613s 547ms/step - loss: 0.5558 - acc: 0.8045 - f1: 0.8096 - val_loss: 0.5696 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 2/10\n",
      "1110/1120 [============================>.] - ETA: 5s - loss: 0.4851 - acc: 0.8207 - f1: 0.8207 Epoch 00002: val_acc did not improve\n",
      "1120/1120 [==============================] - 659s 588ms/step - loss: 0.4856 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5393 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 3/10\n",
      "1110/1120 [============================>.] - ETA: 6s - loss: 0.4807 - acc: 0.8216 - f1: 0.8216 Epoch 00003: val_acc did not improve\n",
      "1120/1120 [==============================] - 727s 649ms/step - loss: 0.4825 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5404 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 4/10\n",
      "1110/1120 [============================>.] - ETA: 7s - loss: 0.4803 - acc: 0.8198 - f1: 0.8198 Epoch 00004: val_acc did not improve\n",
      "1120/1120 [==============================] - 852s 761ms/step - loss: 0.4791 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5320 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 5/10\n",
      "1110/1120 [============================>.] - ETA: 7s - loss: 0.4811 - acc: 0.8198 - f1: 0.8198 Epoch 00005: val_acc did not improve\n",
      "1120/1120 [==============================] - 873s 780ms/step - loss: 0.4799 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5363 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 6/10\n",
      "1110/1120 [============================>.] - ETA: 6s - loss: 0.4760 - acc: 0.8198 - f1: 0.8198 Epoch 00006: val_acc did not improve\n",
      "1120/1120 [==============================] - 777s 693ms/step - loss: 0.4750 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5304 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 7/10\n",
      "1110/1120 [============================>.] - ETA: 6s - loss: 0.4782 - acc: 0.8198 - f1: 0.8198 Epoch 00007: val_acc did not improve\n",
      "1120/1120 [==============================] - 761s 680ms/step - loss: 0.4771 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5322 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 8/10\n",
      "1110/1120 [============================>.] - ETA: 7s - loss: 0.4795 - acc: 0.8189 - f1: 0.8189 Epoch 00008: val_acc did not improve\n",
      "1120/1120 [==============================] - 848s 757ms/step - loss: 0.4774 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5246 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 9/10\n",
      "1110/1120 [============================>.] - ETA: 5s - loss: 0.4741 - acc: 0.8207 - f1: 0.8207 Epoch 00009: val_acc did not improve\n",
      "1120/1120 [==============================] - 648s 579ms/step - loss: 0.4743 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5303 - val_acc: 0.7821 - val_f1: 0.7821\n",
      "Epoch 10/10\n",
      "1110/1120 [============================>.] - ETA: 5s - loss: 0.4730 - acc: 0.8189 - f1: 0.8189 Epoch 00010: val_acc did not improve\n",
      "1120/1120 [==============================] - 657s 587ms/step - loss: 0.4701 - acc: 0.8205 - f1: 0.8205 - val_loss: 0.5582 - val_acc: 0.7821 - val_f1: 0.7821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d391978>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the classification model.\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Let's train the model\n",
    "model_classify.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy', f1])\n",
    "\n",
    "filepath=\"classify.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model_classify.fit(X_train, Y_train, batch_size=batch_size_classify, epochs = nb_epoch_classify, callbacks=callbacks_list, \\\n",
    "          validation_split = 0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_classify.predict(X_test)\n",
    "y_pred_copy = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = y_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "median = np.median(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = mean - std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[x > thresh] = 1\n",
    "x[x < thresh] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[x == 1] = 0\n",
    "x[x == 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84934277,  0.29383886])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test_1, x, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 91s 152ms/step\n",
      "Loss: 0.497973384857\n",
      "Accuracy: 0.813333333333\n",
      "F1: 0.813333273729\n"
     ]
    }
   ],
   "source": [
    "score = model_classify.evaluate(X_test, Y_test)\n",
    "print(\"Loss:\", score[0])\n",
    "print(\"Accuracy:\", score[1])\n",
    "print(\"F1:\", score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
